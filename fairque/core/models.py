"""Core models for FairQueue: Priority, Task, and DLQEntry."""

import dataclasses
import json
import time
import uuid
from dataclasses import dataclass, field
from enum import IntEnum
from typing import Any, Dict, List, Optional

from fairque.core.exceptions import TaskSerializationError


class Priority(IntEnum):
    """Task priority levels with type safety."""

    VERY_LOW = 1    # Lowest priority, minimal time weight
    LOW = 2         # Low priority
    NORMAL = 3      # Standard priority
    HIGH = 4        # High priority
    VERY_HIGH = 5   # Very high priority, maximum time weight
    CRITICAL = 6    # Critical priority, uses separate FIFO queue

    @property
    def weight(self) -> float:
        """Get priority weight for score calculation (1-5 only).

        Returns:
            Priority weight as float between 0.2 and 1.0

        Raises:
            ValueError: If called on CRITICAL priority
        """
        if self == Priority.CRITICAL:
            raise ValueError("Critical priority does not use weight calculation")
        return self.value / 5.0

    @property
    def is_critical(self) -> bool:
        """Check if priority is critical.

        Returns:
            True if priority is CRITICAL, False otherwise
        """
        return self == Priority.CRITICAL

    @classmethod
    def from_int(cls, value: int) -> "Priority":
        """Create Priority from integer with validation.

        Args:
            value: Integer value (1-6)

        Returns:
            Priority enum instance

        Raises:
            ValueError: If value is not in valid range
        """
        try:
            return cls(value)
        except ValueError:
            raise ValueError(f"Invalid priority value: {value}. Must be 1-6.") from None


def calculate_score(task: "Task") -> float:
    """Calculate priority score for normal queue ordering.

    Higher score = higher priority for processing.
    Formula: created_at + (priority_weight * elapsed_time)
    This prevents starvation while respecting priority levels.

    Args:
        task: Task to calculate score for

    Returns:
        Priority score as float

    Raises:
        ValueError: If task has CRITICAL priority
    """
    if task.priority.is_critical:
        raise ValueError("Critical tasks do not use score calculation")

    current_time = time.time()
    elapsed_time = current_time - task.created_at
    priority_weight = task.priority.weight

    return task.created_at + (priority_weight * elapsed_time)


@dataclass
class Task:
    """Optimized Task model with efficient serialization."""

    task_id: str           # UUID4 auto-generated by system
    user_id: str
    priority: Priority     # Priority enum (1-6)
    payload: Dict[str, Any]
    retry_count: int = 0
    max_retries: int = 3
    created_at: float = field(default_factory=time.time)
    execute_after: float = field(default_factory=time.time)

    @classmethod
    def create(
        cls,
        user_id: str,
        priority: Priority,
        payload: Dict[str, Any],
        max_retries: int = 3,
        execute_after: Optional[float] = None,
    ) -> "Task":
        """Create new task with auto-generated UUID and timestamps.

        Args:
            user_id: User identifier
            priority: Task priority
            payload: Task data payload
            max_retries: Maximum retry attempts
            execute_after: Timestamp when task should be executed (defaults to now)

        Returns:
            New Task instance
        """
        current_time = time.time()
        return cls(
            task_id=str(uuid.uuid4()),
            user_id=user_id,
            priority=priority,
            payload=payload,
            retry_count=0,
            max_retries=max_retries,
            created_at=current_time,
            execute_after=execute_after or current_time,
        )

    def is_ready_to_execute(self) -> bool:
        """Check if task is ready to execute based on execute_after timestamp.

        Returns:
            True if task is ready to execute, False otherwise
        """
        return time.time() >= self.execute_after

    def can_retry(self) -> bool:
        """Check if task can be retried.

        Returns:
            True if retry count is below max_retries, False otherwise
        """
        return self.retry_count < self.max_retries

    def get_retry_delay(self) -> float:
        """Calculate exponential backoff delay for retry.

        Returns:
            Delay in seconds for next retry attempt
        """
        return 2.0 ** self.retry_count

    def increment_retry(self) -> "Task":
        """Return new task instance with incremented retry count and updated execute_after.

        Returns:
            New Task instance with incremented retry count
        """
        delay = self.get_retry_delay()
        return dataclasses.replace(
            self,
            retry_count=self.retry_count + 1,
            execute_after=time.time() + delay,
        )

    # Optimized serialization methods
    def to_redis_dict(self) -> Dict[str, str]:
        """Redis storage optimized dictionary (minimized JSON encoding).

        Returns:
            Dictionary with string keys and values for Redis storage
        """
        return {
            "task_id": self.task_id,
            "user_id": self.user_id,
            "priority": str(self.priority.value),  # int as string
            "payload": json.dumps(self.payload, separators=(",", ":")),  # minimal JSON
            "retry_count": str(self.retry_count),
            "max_retries": str(self.max_retries),
            "created_at": f"{self.created_at:.6f}",  # limited precision
            "execute_after": f"{self.execute_after:.6f}",
        }

    @classmethod
    def from_redis_dict(cls, data: Dict[str, str]) -> "Task":
        """Efficiently restore from Redis dictionary.

        Args:
            data: Dictionary from Redis with string keys and values

        Returns:
            Task instance restored from Redis data

        Raises:
            TaskSerializationError: If deserialization fails
        """
        try:
            return cls(
                task_id=data["task_id"],
                user_id=data["user_id"],
                priority=Priority(int(data["priority"])),
                payload=json.loads(data["payload"]),
                retry_count=int(data["retry_count"]),
                max_retries=int(data["max_retries"]),
                created_at=float(data["created_at"]),
                execute_after=float(data["execute_after"]),
            )
        except (KeyError, ValueError, json.JSONDecodeError) as e:
            raise TaskSerializationError(f"Failed to deserialize task from Redis: {e}") from e

    def to_lua_args(self) -> List[str]:
        """Lua script argument list (optimized for array transmission).

        Returns:
            List of string arguments for Lua script
        """
        redis_dict = self.to_redis_dict()
        return [
            redis_dict["task_id"],
            redis_dict["user_id"],
            redis_dict["priority"],
            redis_dict["payload"],
            redis_dict["retry_count"],
            redis_dict["max_retries"],
            redis_dict["created_at"],
            redis_dict["execute_after"],
        ]

    @classmethod
    def from_lua_result(cls, lua_args: List[str]) -> "Task":
        """Restore from Lua script result (optimized array format).

        Args:
            lua_args: List of string arguments from Lua script

        Returns:
            Task instance restored from Lua result

        Raises:
            TaskSerializationError: If deserialization fails
        """
        if len(lua_args) != 8:
            raise TaskSerializationError(
                f"Invalid lua_args length: expected 8, got {len(lua_args)}"
            )

        return cls(
            task_id=lua_args[0],
            user_id=lua_args[1],
            priority=Priority(int(lua_args[2])),
            payload=json.loads(lua_args[3]),
            retry_count=int(lua_args[4]),
            max_retries=int(lua_args[5]),
            created_at=float(lua_args[6]),
            execute_after=float(lua_args[7]),
        )


@dataclass
class DLQEntry:
    """Simplified DLQ entry with failure type embedded."""

    entry_id: str           # UUID4 for DLQ entry
    original_task: Task     # Failed original task
    failure_type: str       # "failed"|"expired"|"poisoned"
    reason: str            # Failure reason description
    moved_at: float        # Timestamp when moved to DLQ
    retry_history: List[Dict[str, Any]] = field(default_factory=list)

    @classmethod
    def create(cls, task: Task, failure_type: str, reason: str) -> "DLQEntry":
        """Create new DLQ entry.

        Args:
            task: Original failed task
            failure_type: Type of failure ("failed", "expired", "poisoned")
            reason: Human-readable failure reason

        Returns:
            New DLQEntry instance
        """
        return cls(
            entry_id=str(uuid.uuid4()),
            original_task=task,
            failure_type=failure_type,
            reason=reason,
            moved_at=time.time(),
            retry_history=[],
        )

    def get_age_seconds(self) -> float:
        """Get age of this DLQ entry in seconds.

        Returns:
            Age in seconds since entry was moved to DLQ
        """
        return time.time() - self.moved_at
